{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, I will do a sentiment analysis with Random Forest Classifier for a supervised dataset containing some tweets and detailed information about regarding tweets. Data can be found [here](https://www.kaggle.com/crowdflower/twitter-airline-sentiment).\n",
    "\n",
    "### Table of contents\n",
    "- [Reading and cleaning the data](#Reading-and-cleaning-the-data)\n",
    "- [Feature engineering](#Feature-engineering)\n",
    "- [Preprocessing](#Preprocessing)\n",
    "- [Model evaluation](#Model-evaluation)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/datht/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/datht/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and cleaning the data\n",
    "I'll start with importing necessary libraries and modules and then read the csv file into pandas dataframe. Then, I will clean the dataset to make it ready for the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[567737449938685952, 'negative', \"@SouthwestAir no flights out of #nashville today? Are you kidding me?!?! Why are other airlines flying and you're not?! So frustrated!!\", 'train']\n",
      "['tweet_id', 'label', 'text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567737449938685952</td>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir no flights out of #nashville tod...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>567737317432258560</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir I am but it says yall are sold o...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567736870365171713</td>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir I'm trying to change a family va...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>567736166787850240</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir F5R3ZZ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>567735766416392194</td>\n",
       "      <td>positive</td>\n",
       "      <td>.@SouthwestAir you've got a mess here at DTW b...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33372</th>\n",
       "      <td>567737962541375490</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir landing early morning @BWI_Airpo...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33373</th>\n",
       "      <td>567737653118779392</td>\n",
       "      <td>positive</td>\n",
       "      <td>@SouthwestAir and thanks!</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33374</th>\n",
       "      <td>567737625637687296</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir sure. Fhk2te. Am scheduled to le...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33375</th>\n",
       "      <td>567737617031380992</td>\n",
       "      <td>positive</td>\n",
       "      <td>@SouthwestAir its all good. flight eventually ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33376</th>\n",
       "      <td>567737554087059457</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir I noticed the rates increased a ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33377 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id     label  \\\n",
       "0      567737449938685952  negative   \n",
       "1      567737317432258560   neutral   \n",
       "2      567736870365171713  negative   \n",
       "3      567736166787850240   neutral   \n",
       "4      567735766416392194  positive   \n",
       "...                   ...       ...   \n",
       "33372  567737962541375490   neutral   \n",
       "33373  567737653118779392  positive   \n",
       "33374  567737625637687296   neutral   \n",
       "33375  567737617031380992  positive   \n",
       "33376  567737554087059457   neutral   \n",
       "\n",
       "                                                    text  split  \n",
       "0      @SouthwestAir no flights out of #nashville tod...  train  \n",
       "1      @SouthwestAir I am but it says yall are sold o...  train  \n",
       "2      @SouthwestAir I'm trying to change a family va...  train  \n",
       "3                                   @SouthwestAir F5R3ZZ  train  \n",
       "4      .@SouthwestAir you've got a mess here at DTW b...  train  \n",
       "...                                                  ...    ...  \n",
       "33372  @SouthwestAir landing early morning @BWI_Airpo...   test  \n",
       "33373                          @SouthwestAir and thanks!   test  \n",
       "33374  @SouthwestAir sure. Fhk2te. Am scheduled to le...   test  \n",
       "33375  @SouthwestAir its all good. flight eventually ...   test  \n",
       "33376  @SouthwestAir I noticed the rates increased a ...   test  \n",
       "\n",
       "[33377 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_data = pd.read_csv(\"/home/datht/sentiment/data/combine/all.csv\", encoding=\"ISO-8859-1\") = pd.read_csv(\"/home/datht/sentiment/data/combine/kfolds_0/train.csv\", encoding=\"ISO-8859-1\")\n",
    "train_df = pd.read_csv(\"/home/datht/sentiment/data/combine/kfolds_0/train.csv\", \n",
    "                       encoding=\"ISO-8859-1\")\n",
    "val_df = pd.read_csv(\"/home/datht/sentiment/data/combine/kfolds_0/test.csv\", \n",
    "                     encoding=\"ISO-8859-1\")\n",
    "all_df = []\n",
    "for values in train_df.values:\n",
    "    values = values.tolist()\n",
    "    values.append('train')\n",
    "    all_df.append(values)\n",
    "for values in val_df.values:\n",
    "    values = values.tolist()\n",
    "    values.append('test')\n",
    "    all_df.append(values)\n",
    "print(all_df[0])\n",
    "columns = train_df.columns\n",
    "print(columns.tolist())\n",
    "data = pd.DataFrame(all_df, columns=train_df.columns.tolist() + ['split'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there are many information in this dataset, I'll be using only two columns which are 'airline_sentiment' and 'text'. So, let's start with creating a new dataframe for that information only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir no flights out of #nashville tod...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir I am but it says yall are sold o...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir I'm trying to change a family va...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@SouthwestAir F5R3ZZ</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>.@SouthwestAir you've got a mess here at DTW b...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  split\n",
       "0  negative  @SouthwestAir no flights out of #nashville tod...  train\n",
       "1   neutral  @SouthwestAir I am but it says yall are sold o...  train\n",
       "2  negative  @SouthwestAir I'm trying to change a family va...  train\n",
       "3   neutral                               @SouthwestAir F5R3ZZ  train\n",
       "4  positive  .@SouthwestAir you've got a mess here at DTW b...  train"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataframe for only two columns\n",
    "tweets = data.loc[:,['label','text', 'split']]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the rows in 'text' column contains many words and punctuations that I will not need for analysis, I'll clean those first. In this step, I'll remove all punctuations, mentions in tweets (the words starting with @), convert everything to lower case, tokenize and lemmatize the words and remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>[flight, nashville, today, kidding, airline, f...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[say, yall, sold, amp, coworkers, would, need,...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>[im, trying, change, family, vacation, due, me...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[f5r3zz]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>[youve, got, mess, dtw, staff, great]</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  split\n",
       "0  negative  [flight, nashville, today, kidding, airline, f...  train\n",
       "1   neutral  [say, yall, sold, amp, coworkers, would, need,...  train\n",
       "2  negative  [im, trying, change, family, vacation, due, me...  train\n",
       "3   neutral                                           [f5r3zz]  train\n",
       "4  positive              [youve, got, mess, dtw, staff, great]  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean and tokenize the data\n",
    "class RandomForestTextPreprocessing():\n",
    "    def __init__(self):\n",
    "        self.stopword = nltk.corpus.stopwords.words('english')\n",
    "        self.wn = nltk.WordNetLemmatizer()\n",
    "    \n",
    "    def clean_tokenize_text(self, text):\n",
    "        # Remove mentions starting with @\n",
    "        text = re.sub('@\\w+\\s', '', text)\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = ''.join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "        text = text.lower()\n",
    "\n",
    "        # Tokenize the text\n",
    "        tokens = re.split('\\W+', text)\n",
    "\n",
    "        # Remove stopwords\n",
    "        text = [word for word in tokens if word not in self.stopword]\n",
    "\n",
    "        # Lemmatize the words\n",
    "        text = [self.wn.lemmatize(word) for word in text]\n",
    "\n",
    "        # Return text\n",
    "        return text\n",
    "\n",
    "\n",
    "# Apply the function to text column\n",
    "cleaner = RandomForestTextPreprocessing()\n",
    "tweets['text'] = tweets['text'].apply(lambda x: cleaner.clean_tokenize_text(x))\n",
    "\n",
    "# Display first five rows\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature engineering\n",
    "\n",
    "In this step, I want to see if creating a new feature may have any impact on model's performance in next steps. As a new feature, text length may be added to see if negative, neutral or positive tweets have much difference in text length. For this purpose, I will use the character count in tweets in the uncleaned dataset. It includes mentions as well, but since it's a dataset consists of tweets which were written to airlines, almost all of them should include mentions in them. Even if they don't, it's not important in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body</th>\n",
       "      <th>split</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>[flight, nashville, today, kidding, airline, f...</td>\n",
       "      <td>train</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[say, yall, sold, amp, coworkers, would, need,...</td>\n",
       "      <td>train</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>[im, trying, change, family, vacation, due, me...</td>\n",
       "      <td>train</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[f5r3zz]</td>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>[youve, got, mess, dtw, staff, great]</td>\n",
       "      <td>train</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               body  split  \\\n",
       "0  negative  [flight, nashville, today, kidding, airline, f...  train   \n",
       "1   neutral  [say, yall, sold, amp, coworkers, would, need,...  train   \n",
       "2  negative  [im, trying, change, family, vacation, due, me...  train   \n",
       "3   neutral                                           [f5r3zz]  train   \n",
       "4  positive              [youve, got, mess, dtw, staff, great]  train   \n",
       "\n",
       "   text_len  \n",
       "0       115  \n",
       "1        89  \n",
       "2       113  \n",
       "3        19  \n",
       "4        62  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column for character count in a tweet\n",
    "tweets['text_len'] = data['text'].apply(lambda x: len(x) - x.count(' '))\n",
    "\n",
    "# Rename the columns\n",
    "tweets.columns=['label','body', 'split', 'text_len']\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the density distribution of character counts in every tweet in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from matplotlib import pyplot as plt\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Create a density plot for character counts for each label\n",
    "# bins = np.linspace(0,140,35)\n",
    "# sns.distplot(tweets[tweets['label']=='negative']['text_len'], bins, label='negative')\n",
    "# sns.distplot(tweets[tweets['label']=='positive']['text_len'], bins, label='positive')\n",
    "# sns.distplot(tweets[tweets['label']=='neutral']['text_len'], bins, label='neutral')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like while the distribution character counts in neutral and positive tweets almost the same, negative tweets have more characters then the others. It might be because people tend to write more characters when they are angry or upset or complaining about something to explain the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Now, I'll split train and test set and vectorize them with TF-IDF Vectorizer. But first, I'll create the dataset again to be used in the model because this time I will not clean and tokenize the dataset before splitting text and train sets since TF-IDF Vectorizer does it already with the function passed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_inds = [i for i, split in enumerate(tweets['split'].values) if split == 'train']\n",
    "test_inds = [i for i, split in enumerate(tweets['split'].values) if split == 'test']\n",
    "\n",
    "# X_train = data.values[train_inds]\n",
    "# X_test = data.values[test_inds]\n",
    "# y_train = data[].values[train_inds]\n",
    "# y_test = data[sentiment].values[test_inds]\n",
    "\n",
    "\n",
    "# Create a new dataframe for 'airline_sentiment' and 'text' columns\n",
    "# data = data.loc[:,['label','text']]\n",
    "\n",
    "# Rename the columns\n",
    "# data.columns = ['label', 'body']\n",
    "\n",
    "# Create a column for character counts in each tweet except for white spaces\n",
    "# data['text_len'] = data['body'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "tweets['body'] = tweets['body'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Import module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train = tweets[['body','text_len']].iloc[train_inds]\n",
    "X_test = tweets[['body', 'text_len']].iloc[test_inds]\n",
    "\n",
    "y_train = tweets[['label']].iloc[train_inds]\n",
    "y_test = tweets[['label']].iloc[test_inds]\n",
    "\n",
    "# Split train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data[['body', 'text_len']], data['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the text\n",
    "After creating a TF-IDF Vectorizer, I will only fit the train set because I don't want it to know the words in test set. Giving all the data to the model to fit may impact test set accuracy in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>36129</th>\n",
       "      <th>36130</th>\n",
       "      <th>36131</th>\n",
       "      <th>36132</th>\n",
       "      <th>36133</th>\n",
       "      <th>36134</th>\n",
       "      <th>36135</th>\n",
       "      <th>36136</th>\n",
       "      <th>36137</th>\n",
       "      <th>36138</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len    0    1    2    3    4    5    6    7    8  ...  36129  36130  \\\n",
       "0       115  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1        89  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2       113  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "3        19  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4        62  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "   36131  36132  36133  36134  36135  36136  36137  36138  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 36140 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a TF-IDF Vectorizer\n",
    "# tfidf_vect = TfidfVectorizer(analyzer=cleaner.clean_tokenize_text)\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "# Fit the train set\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['body'])\n",
    "\n",
    "# Transform train and test sets\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['body'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['body'])\n",
    "\n",
    "# Create new dataframe for train and test sets including 'text_len' column\n",
    "X_train_vect = pd.concat([X_train['text_len'].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "\n",
    "X_test_vect = pd.concat([X_test['text_len'].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "# Display first 5 rows of vectorized train set\n",
    "X_train_vect.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a tf-idf vectorized dataframe for every word in the dataset. Also, I've added text_len feature to it. Let's see some of the feature names that appear in our vectorized dataset in the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '0000', '002013', '0030', '003045', '006', '007', '01', '012', '0120']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datht/sentiment/.env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Get the first 10 feature names in whole dataset\n",
    "print(tfidf_vect.get_feature_names()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Let's try Grid Search for Random Forest Classifier to find the most ideal hyperparameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import cross validation score evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Define parameters\n",
    "# param = {\n",
    "#     'n_estimators': [10, 50, 100], \n",
    "#     'max_depth': [10, 20, 30, None],\n",
    "#     }\n",
    "\n",
    "# # Create a model\n",
    "# clf = GridSearchCV(RandomForestClassifier(), param,cv=5, n_jobs=None)\n",
    "\n",
    "# # Fit the vectorized train set\n",
    "# rf_model = clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# # Create a dataframe for the cross validation results\n",
    "# pd.DataFrame(rf_model.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like random forest classifier with n_estimators=100 or n_estimators=50 and max_depth=None parameters would give us the best result with 0.75 mean test score for this dataset. Let's finalize our model with the given hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing the model\n",
    "I will set the hyperparameters to the ones that grid search gave the best result with and calculate some evaluation metrics to see the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datht/sentiment/.env/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_59512/1783982575.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_model = rf_class.fit(X_train_vect, y_train)\n"
     ]
    }
   ],
   "source": [
    "# Create a model with defined parameters\n",
    "rf_class = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1)\n",
    "\n",
    "# Fit the vectorized train set to the model\n",
    "rf_model = rf_class.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.018833234814762442, 'text_len'),\n",
       " (0.013802397621430533, 10550),\n",
       " (0.006524073867895912, 32587),\n",
       " (0.005972862644726056, 33144),\n",
       " (0.005750952656552147, 32579),\n",
       " (0.005715241725625991, 13011),\n",
       " (0.00538816755240984, 33699),\n",
       " (0.005201073713438528, 22940),\n",
       " (0.005141713979431103, 7548),\n",
       " (0.004448945356718828, 23886)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances with feature names\n",
    "sorted(zip(rf_model.feature_importances_, X_train_vect.columns), reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datht/sentiment/.env/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: micro: 0.718\n",
      "Precision: micro-macro: 0.718-0.674\n",
      "Recall: micro-macro: 0.718-0.624\n",
      "F1: micro-macro: 0.718-0.643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.87      0.82      3956\n",
      "     neutral       0.56      0.45      0.50      1515\n",
      "    positive       0.70      0.55      0.61      1205\n",
      "\n",
      "    accuracy                           0.72      6676\n",
      "   macro avg       0.67      0.62      0.64      6676\n",
      "weighted avg       0.71      0.72      0.71      6676\n",
      "\n",
      "660 688 3448\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_model.predict(X_test_vect)\n",
    "\n",
    "result1 = y_pred\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_test, result1)\n",
    "print(f'Accuracy: micro: {acc:.3f}')\n",
    "\n",
    "p_micro = precision_score(y_test, result1, average='micro')\n",
    "p_macro = precision_score(y_test, result1, average='macro')\n",
    "print(f'Precision: micro-macro: {p_micro:.3f}-{p_macro:.3f}')\n",
    "\n",
    "r_micro = recall_score(y_test, result1, average='micro')\n",
    "r_macro = recall_score(y_test, result1, average='macro')\n",
    "print(f'Recall: micro-macro: {r_micro:.3f}-{r_macro:.3f}')\n",
    "\n",
    "f1_micro = f1_score(y_test, result1, average='micro')\n",
    "f1_macro = f1_score(y_test, result1, average='macro')\n",
    "print(f'F1: micro-macro: {f1_micro:.3f}-{f1_macro:.3f}')\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, result1, target_names=[\"negative\", \"neutral\", \"positive\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "n_true_pos = 0\n",
    "n_true_neu = 0\n",
    "n_true_neg = 0\n",
    "for p, l in zip(result1, y_test.values):\n",
    "    if p == l and l == 'positive':\n",
    "        n_true_pos += 1\n",
    "    elif p == l and l == 'neutral':\n",
    "        n_true_neu += 1\n",
    "    elif p == l and l == 'negative':\n",
    "        n_true_neg += 1\n",
    "print(n_true_pos, n_true_neu, n_true_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the feature 'text_len' that gives the character count for each tweet has the best impact on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datht/sentiment/.env/lib/python3.9/site-packages/sklearn/utils/validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "# Predict the vectorized test set\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "\n",
    "# Get scores\n",
    "precision, recall, fscore, support = score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# import joblib\n",
    "# joblib.dump(rf_model, 'rf_model.pkl')\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "pkl.dump({\n",
    "    'model': rf_model,\n",
    "    'vectorizer': tfidf_vect\n",
    "}, open('../models/random_forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.87      0.82      3956\n",
      "     neutral       0.56      0.45      0.50      1515\n",
      "    positive       0.70      0.55      0.61      1205\n",
      "\n",
      "    accuracy                           0.72      6676\n",
      "   macro avg       0.67      0.62      0.64      6676\n",
      "weighted avg       0.71      0.72      0.71      6676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the model is the best in predicting 'negative' tweets correctly with 0.77 precision, 0.95 recall and 0.85 f-1 scores. And it's not as good in predicting the other classes. But overall, it has 76.0% accuracy rate in predicting which class a tweet belongs to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
